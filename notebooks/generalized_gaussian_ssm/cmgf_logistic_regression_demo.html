
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Online Logistic Regression using conditional moments Gaussian filter</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/generalized_gaussian_ssm/cmgf_logistic_regression_demo';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Online learning of an MLP Classifier using conditional moments Gaussian filter" href="cmgf_mlp_classification_demo.html" />
    <link rel="prev" title="Online learning for an MLP using extended Kalman filtering" href="../nonlinear_gaussian_ssm/ekf_mlp.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.gif" class="logo__image only-light" alt=" - Home"/>
    <script>document.write(`<img src="../../_static/logo.gif" class="logo__image only-dark" alt=" - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">HMMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hmm/casino_hmm_inference.html">Casino HMM: Inference (state estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/casino_hmm_learning.html">Casino HMM: Learning (parameter estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/gaussian_hmm.html">Gaussian HMM: Cross-validation and Model Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/autoregressive_hmm.html">Autoregressive (AR) HMM Demo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Gaussian SSMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/kf_tracking.html">Tracking an object using the Kalman filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/kf_linreg.html">Online linear regression using Kalman filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_parallel_inference.html">Parallel filtering and smoothing in an LG-SSM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_learning.html">MAP parameter estimation for an LG-SSM using EM and SGD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_hmc.html">Bayesian parameter estimation for an LG-SSM using HMC</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Nonlinear Gaussian SSMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_ukf_spiral.html">Tracking a spiraling object using the extended / unscented Kalman filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_ukf_pendulum.html">Tracking a 1d pendulum using Extended / Unscented Kalman filter/ smoother</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_mlp.html">Online learning for an MLP using extended Kalman filtering</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generalized Gaussian SSMs</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Online Logistic Regression using conditional moments Gaussian filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cmgf_mlp_classification_demo.html">Online learning of an MLP Classifier using conditional moments Gaussian filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cmgf_poisson_demo.html">Fitting an LDS with Poisson Likelihood using conditional moments Gaussian filter</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../types.html">Terminology for types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">State Space Model (Base class)</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/probml/dynamax/main?urlpath=tree/docs/notebooks/generalized_gaussian_ssm/cmgf_logistic_regression_demo.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/probml/dynamax/blob/main/docs/notebooks/generalized_gaussian_ssm/cmgf_logistic_regression_demo.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/probml/dynamax" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Online Logistic Regression using conditional moments Gaussian filter</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-and-plotting">Simulation and Plotting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplace-estimate">Laplace Estimate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamical-model">Dynamical model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-inference">Online inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ekf">EKF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ukf">UKF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ghkf">GHKF</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="online-logistic-regression-using-conditional-moments-gaussian-filter">
<h1>Online Logistic Regression using conditional moments Gaussian filter<a class="headerlink" href="#online-logistic-regression-using-conditional-moments-gaussian-filter" title="Link to this heading">#</a></h1>
<p>Online training of a logistic regression model using conditional moments Gaussian filter (CMGF).</p>
<p>We perform sequential (recursive) Bayesian inference for the parameters of a binary logistic regression model.
To do this, we treat the parameters of the model as the unknown hidden states.
We assume that these are approximately constant over time (we add a small amount of Gaussian drift,
for numerical stability.)
The graphical model is shown below.</p>
<p><img alt="RLS" src="https://github.com/probml/dynamax/blob/main/docs/figures/rlsDgm.png?raw=true" /></p>
<p>The model has the following form</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\theta_t &amp;=  \theta_{t-1} + q_t, \; q_t \sim N(0, 0.01 I)  \\
y_t &amp;\sim Ber(\sigma(\theta_t^T x_t))
\end{align*}\]</div>
<p>This is a generalized Gaussian SSM, where the observation model is non-Gaussian.</p>
<p>To perform approximate inference, using the conditional moments Gaussian filter (CMGF).
We approximate the relevant integrals using 3 different methods: linearization (extended Kalman filter),
sigma point approximation (unscented kalman filter), and Gauss hermite integration (order 5).
We compare results with the offline (batch) Laplace approximation, and see that GHKF converges fastest to the batch solution,
but is also slower.
For more details, see sec 8.7.7 of <a class="reference external" href="https://probml.github.io/pml-book/book2.html">Probabilistic Machine Learning: Advanced Topics</a>.</p>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dynamax</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;installing dynamax&#39;</span><span class="p">)</span>
    <span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">dynamax</span><span class="p">[</span><span class="n">notebooks</span><span class="p">]</span>
    <span class="kn">import</span> <span class="nn">dynamax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dynamax.generalized_gaussian_ssm</span> <span class="kn">import</span> <span class="n">ParamsGGSSM</span><span class="p">,</span> <span class="n">EKFIntegrals</span><span class="p">,</span> <span class="n">UKFIntegrals</span><span class="p">,</span> <span class="n">GHKFIntegrals</span>
<span class="kn">from</span> <span class="nn">dynamax.generalized_gaussian_ssm</span> <span class="kn">import</span> <span class="n">conditional_moments_gaussian_filter</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax.random</span> <span class="k">as</span> <span class="nn">jr</span>
<span class="kn">from</span> <span class="nn">jax.scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="simulation-and-plotting">
<h2>Simulation and Plotting<a class="headerlink" href="#simulation-and-plotting" title="Link to this heading">#</a></h2>
<p>We generate a reasonable 2d binary classification data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_dataset</span><span class="p">(</span><span class="n">num_points</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">key0</span><span class="p">,</span> <span class="n">key1</span><span class="p">,</span> <span class="n">key2</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Generate standardized noisy inputs that correspond to output &#39;0&#39;</span>
    <span class="n">num_zero_points</span> <span class="o">=</span> <span class="n">num_points</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">zero_input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]</span> <span class="o">*</span> <span class="n">num_zero_points</span><span class="p">)</span>
    <span class="n">zero_input</span> <span class="o">+=</span> <span class="n">jr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key0</span><span class="p">,</span> <span class="p">(</span><span class="n">num_zero_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Generate standardized noisy inputs that correspond to output &#39;1&#39;</span>
    <span class="n">num_one_points</span> <span class="o">=</span> <span class="n">num_points</span> <span class="o">-</span> <span class="n">num_zero_points</span>
    <span class="n">one_input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]</span> <span class="o">*</span> <span class="n">num_one_points</span><span class="p">)</span>
    <span class="n">one_input</span> <span class="o">+=</span> <span class="n">jr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key1</span><span class="p">,</span> <span class="p">(</span><span class="n">num_one_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Stack the inputs and add bias term</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">zero_input</span><span class="p">,</span> <span class="n">one_input</span><span class="p">])</span>
    <span class="n">input_with_bias</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_points</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="nb">input</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Generate binary output</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_zero_points</span><span class="p">)),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_one_points</span><span class="p">))])</span>

    <span class="c1"># Shuffle</span>
    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">key2</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_points</span><span class="p">))</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">input_with_bias</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">input_with_bias</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_with_bias</span><span class="p">,</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate data</span>
<span class="nb">input</span><span class="p">,</span> <span class="n">input_with_bias</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">generate_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2000/1437855553.py:25: DeprecationWarning: jax.random.shuffle is deprecated. Use jax.random.permutation with independent=True.
  idx = jr.shuffle(key2, jnp.arange(num_points))
/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/jax/_src/random.py:535: FutureWarning: jax.random.shuffle is deprecated and will be removed in a future release. Use jax.random.permutation with independent=True.
  warnings.warn(msg, FutureWarning)
</pre></div>
</div>
</div>
</div>
<p>Next, we define a function that visualizes the 2d posterior predictive distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">Xspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Zspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">Xspace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Zspace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="o">*</span><span class="n">Xspace</span><span class="p">,</span> <span class="n">Zspace</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_boundary</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">Xspace</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xspace</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">Xspace</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Letâ€™s look at our binary data in 2d.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Binary classification data&quot;</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;black&#39;</span> <span class="k">if</span> <span class="n">y</span> <span class="k">else</span> <span class="s1">&#39;red&#39;</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">output</span><span class="p">]</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">colors</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/aafc29924b4dd524bab4427ea9ab576c0ee2e5496685c5f23b226457d1a7910c.png" src="../../_images/aafc29924b4dd524bab4427ea9ab576c0ee2e5496685c5f23b226457d1a7910c.png" />
</div>
</div>
<p>Let us define a grid on which we compute the predictive distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define grid limits</span>
<span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.1</span>
<span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span>

<span class="c1"># Define grid</span>
<span class="n">step</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">input_grid</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="n">xmin</span><span class="p">:</span><span class="n">xmax</span><span class="p">:</span><span class="n">step</span><span class="p">,</span> <span class="n">ymin</span><span class="p">:</span><span class="n">ymax</span><span class="p">:</span><span class="n">step</span><span class="p">]</span>
<span class="n">_</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="n">ny</span> <span class="o">=</span> <span class="n">input_grid</span><span class="o">.</span><span class="n">shape</span>
<span class="n">input_with_bias_grid</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nx</span><span class="p">,</span> <span class="n">ny</span><span class="p">)),</span> <span class="n">input_grid</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we define a function to that returns the posterior predictive probability for each point in grid.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">posterior_predictive_grid</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;mij,sm-&gt;sij&quot;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">samples</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Z</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we define a function that plots the convergence of filtered estimates to the batch MAP estimate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_cmgf_post_laplace</span><span class="p">(</span>
    <span class="n">mean_hist</span><span class="p">,</span> <span class="n">cov_hist</span><span class="p">,</span> <span class="n">w_map</span><span class="p">,</span> <span class="n">lcolors</span><span class="p">,</span> <span class="n">filter_type</span><span class="p">,</span> <span class="n">legend_font_size</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">bb1</span><span class="o">=</span><span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">),</span> <span class="n">bb2</span><span class="o">=</span><span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="n">bb3</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="p">):</span>
    <span class="n">input_dim</span> <span class="o">=</span> <span class="n">mean_hist</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tau_hist</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">cov_hist</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_dim</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">elements</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean_hist</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">tau_hist</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">w_map</span><span class="p">,</span> <span class="n">lcolors</span><span class="p">)</span>
    <span class="n">n_datapoints</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mean_hist</span><span class="p">)</span>
    <span class="n">timesteps</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_datapoints</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">wk</span><span class="p">,</span> <span class="n">Pk</span><span class="p">,</span> <span class="n">wk_fix</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">elements</span><span class="p">)):</span>
        <span class="n">fig_weight_k</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">wk</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Pk</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;$w_</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">$ online (</span><span class="si">{</span><span class="n">filter_type</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">wk_fix</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dotted&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;$w_</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">$ batch (Laplace)&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_datapoints</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;ordered sample number&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;weight value&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="n">bb1</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">legend_font_size</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="n">bb2</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">legend_font_size</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="n">bb3</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">legend_font_size</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="laplace-estimate">
<h2>Laplace Estimate<a class="headerlink" href="#laplace-estimate" title="Link to this heading">#</a></h2>
<p>We compute a Laplace approximation to the posterior, which we can compare CMGF to.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_posterior</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">prior_var</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">log_prior</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">prior_var</span> <span class="o">*</span> <span class="n">w</span> <span class="o">@</span> <span class="n">w</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_prior</span> <span class="o">+</span> <span class="n">log_likelihood</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">laplace_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">prior_var</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">input_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Initial random guess</span>
    <span class="n">w0</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_dim</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">input_dim</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior_var</span><span class="p">)</span>
    
    <span class="c1"># Energy function to minimize</span>
    <span class="n">E</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="o">-</span><span class="n">log_posterior</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">prior_var</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

    <span class="c1"># Minimize energy function</span>
    <span class="n">w_laplace</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">E</span><span class="p">,</span> <span class="n">w0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;BFGS&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">x</span>
    <span class="n">cov_laplace</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">E</span><span class="p">)(</span><span class="n">w_laplace</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">w_laplace</span><span class="p">,</span> <span class="n">cov_laplace</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute Laplace posterior</span>
<span class="n">prior_var</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">w_laplace</span><span class="p">,</span> <span class="n">cov_laplace</span> <span class="o">=</span> <span class="n">laplace_inference</span><span class="p">(</span><span class="n">input_with_bias</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">prior_var</span><span class="o">=</span><span class="n">prior_var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_adf</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">plot_boundary</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">w_laplace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/729fded912a19238468cfc447492ccc19e9706692ba1375af54d78f8311b63e9.png" src="../../_images/729fded912a19238468cfc447492ccc19e9706692ba1375af54d78f8311b63e9.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_adf</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Plot Laplace posterior predictive distribution</span>
<span class="n">Z_laplace</span> <span class="o">=</span> <span class="n">posterior_predictive_grid</span><span class="p">(</span><span class="n">input_with_bias_grid</span><span class="p">,</span> <span class="n">w_laplace</span><span class="p">,</span> <span class="n">cov_laplace</span><span class="p">)</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Laplace Predictive Distribution&quot;</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">Z_laplace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ef46c8ef8d2934f3f8f67a25a65bd2346dda7f403f626f07120c841571569a2d.png" src="../../_images/ef46c8ef8d2934f3f8f67a25a65bd2346dda7f403f626f07120c841571569a2d.png" />
</div>
</div>
</section>
<section id="dynamical-model">
<h2>Dynamical model<a class="headerlink" href="#dynamical-model" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_with_bias</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">state_dim</span> <span class="o">=</span> <span class="n">input_dim</span> <span class="c1"># linear model</span>
<span class="n">sigmoid_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">w</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># Initial parameters for all CMGF methods</span>
<span class="n">initial_mean</span><span class="p">,</span> <span class="n">initial_covariance</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">state_dim</span><span class="p">),</span> <span class="n">prior_var</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">state_dim</span><span class="p">)</span>
<span class="n">dynamics_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">w</span>
<span class="n">dynamics_covariance</span> <span class="o">=</span> <span class="mf">1e-5</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">state_dim</span><span class="p">)</span>
<span class="n">emission_mean_function</span> <span class="o">=</span> <span class="n">sigmoid_fn</span>
<span class="n">emission_cov_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cmgf_params</span> <span class="o">=</span> <span class="n">ParamsGGSSM</span><span class="p">(</span>
    <span class="n">initial_mean</span> <span class="o">=</span> <span class="n">initial_mean</span><span class="p">,</span>
    <span class="n">initial_covariance</span> <span class="o">=</span> <span class="n">initial_covariance</span><span class="p">,</span>
    <span class="n">dynamics_function</span> <span class="o">=</span> <span class="n">dynamics_function</span><span class="p">,</span>
    <span class="n">dynamics_covariance</span> <span class="o">=</span> <span class="n">dynamics_covariance</span><span class="p">,</span>
    <span class="n">emission_mean_function</span> <span class="o">=</span> <span class="n">emission_mean_function</span><span class="p">,</span>
    <span class="n">emission_cov_function</span> <span class="o">=</span> <span class="n">emission_cov_function</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="online-inference">
<h2>Online inference<a class="headerlink" href="#online-inference" title="Link to this heading">#</a></h2>
<section id="ekf">
<h3>EKF<a class="headerlink" href="#ekf" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run CMGF-EKF and extract final estimates for moments</span>
<span class="n">ekf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_params</span><span class="p">,</span> <span class="n">EKFIntegrals</span><span class="p">(),</span> <span class="n">output</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">input_with_bias</span><span class="p">)</span>
<span class="n">ekf_means</span><span class="p">,</span> <span class="n">ekf_covs</span> <span class="o">=</span> <span class="n">ekf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">ekf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
<span class="n">w_ekf</span><span class="p">,</span> <span class="n">cov_ekf</span> <span class="o">=</span> <span class="n">ekf_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ekf_covs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">fig_adf</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Plot posterior predictive distribution</span>
<span class="n">Z_ekf</span> <span class="o">=</span> <span class="n">posterior_predictive_grid</span><span class="p">(</span><span class="n">input_with_bias_grid</span><span class="p">,</span> <span class="n">w_ekf</span><span class="p">,</span> <span class="n">cov_ekf</span><span class="p">)</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;CMGF-EKF Predictive Distribution&quot;</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">Z_ekf</span><span class="p">)</span>

<span class="c1"># Plot convergence over time to MAP estimate</span>
<span class="n">lcolors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span> <span class="s2">&quot;tab:red&quot;</span><span class="p">]</span>
<span class="n">plot_cmgf_post_laplace</span><span class="p">(</span><span class="n">ekf_means</span><span class="p">[::</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">//</span><span class="mi">100</span><span class="p">)],</span> <span class="n">ekf_covs</span><span class="p">[::</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">//</span><span class="mi">100</span><span class="p">)],</span> <span class="n">w_laplace</span><span class="p">,</span> <span class="n">lcolors</span><span class="p">,</span> <span class="n">filter_type</span><span class="o">=</span><span class="s2">&quot;CMGF-EKF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">18</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Run CMGF-EKF and extract final estimates for moments</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">ekf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_params</span><span class="p">,</span> <span class="n">EKFIntegrals</span><span class="p">(),</span> <span class="n">output</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">input_with_bias</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">ekf_means</span><span class="p">,</span> <span class="n">ekf_covs</span> <span class="o">=</span> <span class="n">ekf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">ekf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">w_ekf</span><span class="p">,</span> <span class="n">cov_ekf</span> <span class="o">=</span> <span class="n">ekf_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ekf_covs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:258,</span> in <span class="ni">conditional_moments_gaussian_filter</span><span class="nt">(model_params, inf_params, emissions, num_iter, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span> <span class="c1"># Run the general linearization filter</span>
<span class="g g-Whitespace">    </span><span class="mi">257</span> <span class="n">carry</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">model_params</span><span class="o">.</span><span class="n">initial_mean</span><span class="p">,</span> <span class="n">model_params</span><span class="o">.</span><span class="n">initial_covariance</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">258</span> <span class="p">(</span><span class="n">ll</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="p">(</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">filtered_covs</span><span class="p">)</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">_step</span><span class="p">,</span> <span class="n">carry</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_timesteps</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">259</span> <span class="k">return</span> <span class="n">PosteriorGSSMFiltered</span><span class="p">(</span><span class="n">marginal_loglik</span><span class="o">=</span><span class="n">ll</span><span class="p">,</span> <span class="n">filtered_means</span><span class="o">=</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">filtered_covariances</span><span class="o">=</span><span class="n">filtered_covs</span><span class="p">)</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">9</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:248,</span> in <span class="ni">conditional_moments_gaussian_filter.&lt;locals&gt;._step</span><span class="nt">(carry, t)</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span> <span class="n">y</span> <span class="o">=</span> <span class="n">emissions</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">247</span> <span class="c1"># Condition on the emission</span>
<span class="ne">--&gt; </span><span class="mi">248</span> <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">filtered_mean</span><span class="p">,</span> <span class="n">filtered_cov</span> <span class="o">=</span> <span class="n">_condition_on</span><span class="p">(</span><span class="n">pred_mean</span><span class="p">,</span> <span class="n">pred_cov</span><span class="p">,</span> <span class="n">m_Y</span><span class="p">,</span> <span class="n">Cov_Y</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">g_ev</span><span class="p">,</span> <span class="n">g_cov</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">,</span> <span class="n">emission_dist</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="n">ll</span> <span class="o">+=</span> <span class="n">log_likelihood</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span> <span class="c1"># Predict the next state</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:171,</span> in <span class="ni">_condition_on</span><span class="nt">(m, P, y_cond_mean, y_cond_cov, u, y, g_ev, g_cov, num_iter, emission_dist)</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span> <span class="c1"># Iterate re-linearization over posterior mean and covariance</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span> <span class="n">carry</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">171</span> <span class="p">(</span><span class="n">mu_cond</span><span class="p">,</span> <span class="n">Sigma_cond</span><span class="p">),</span> <span class="n">lls</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">_step</span><span class="p">,</span> <span class="n">carry</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_iter</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span> <span class="k">return</span> <span class="n">lls</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mu_cond</span><span class="p">,</span> <span class="n">Sigma_cond</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">9</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:162,</span> in <span class="ni">_condition_on.&lt;locals&gt;._step</span><span class="nt">(carry, _)</span>
<span class="g g-Whitespace">    </span><span class="mi">160</span> <span class="n">yhat</span> <span class="o">=</span> <span class="n">g_ev</span><span class="p">(</span><span class="n">m_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">161</span> <span class="n">S</span> <span class="o">=</span> <span class="n">g_ev</span><span class="p">(</span><span class="n">Cov_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span> <span class="o">+</span> <span class="n">g_cov</span><span class="p">(</span><span class="n">m_Y</span><span class="p">,</span> <span class="n">m_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">162</span> <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">emission_dist</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span> <span class="n">C</span> <span class="o">=</span> <span class="n">g_cov</span><span class="p">(</span><span class="n">identity_fn</span><span class="p">,</span> <span class="n">m_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span> <span class="n">K</span> <span class="o">=</span> <span class="n">psd_solve</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/models.py:52,</span> in <span class="ni">ParamsGGSSM.&lt;lambda&gt;</span><span class="nt">(mean, cov)</span>
<span class="g g-Whitespace">     </span><span class="mi">50</span> <span class="n">emission_mean_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">FnStateToEmission</span><span class="p">,</span> <span class="n">FnStateAndInputToEmission</span><span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span> <span class="n">emission_cov_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">FnStateToEmission2</span><span class="p">,</span> <span class="n">FnStateAndInputToEmission2</span><span class="p">]</span>
<span class="ne">---&gt; </span><span class="mi">52</span> <span class="n">emission_dist</span><span class="p">:</span> <span class="n">EmissionDistFn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">:</span> <span class="n">MVN</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/mvn_full_covariance.py:191,</span> in <span class="ni">MultivariateNormalFullCovariance.__init__</span><span class="nt">(self, loc, covariance_matrix, validate_args, allow_nan_stats, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">185</span>       <span class="c1"># No need to validate that covariance_matrix is non-singular.</span>
<span class="g g-Whitespace">    </span><span class="mi">186</span>       <span class="c1"># LinearOperatorLowerTriangular has an assert_non_singular method that</span>
<span class="g g-Whitespace">    </span><span class="mi">187</span>       <span class="c1"># is called by the Bijector.</span>
<span class="g g-Whitespace">    </span><span class="mi">188</span>       <span class="c1"># However, cholesky() ignores the upper triangular part, so we do need</span>
<span class="g g-Whitespace">    </span><span class="mi">189</span>       <span class="c1"># to separately assert symmetric.</span>
<span class="g g-Whitespace">    </span><span class="mi">190</span>       <span class="n">scale_tril</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">191</span>     <span class="nb">super</span><span class="p">(</span><span class="n">MultivariateNormalFullCovariance</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">192</span>         <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">193</span>         <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale_tril</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">194</span>         <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span>         <span class="n">allow_nan_stats</span><span class="o">=</span><span class="n">allow_nan_stats</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">196</span>         <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">197</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">parameters</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/mvn_tril.py:228,</span> in <span class="ni">MultivariateNormalTriL.__init__</span><span class="nt">(self, loc, scale_tril, validate_args, allow_nan_stats, experimental_use_kahan_sum, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span>   <span class="n">linop_cls</span> <span class="o">=</span> <span class="p">(</span><span class="n">KahanLogDetLinOpTriL</span> <span class="k">if</span> <span class="n">experimental_use_kahan_sum</span> <span class="k">else</span>
<span class="g g-Whitespace">    </span><span class="mi">222</span>                <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorLowerTriangular</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">223</span>   <span class="n">scale</span> <span class="o">=</span> <span class="n">linop_cls</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">224</span>       <span class="n">scale_tril</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">225</span>       <span class="n">is_non_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">226</span>       <span class="n">is_self_adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">227</span>       <span class="n">is_positive_definite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">228</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultivariateNormalTriL</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">229</span>     <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span>     <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">232</span>     <span class="n">allow_nan_stats</span><span class="o">=</span><span class="n">allow_nan_stats</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">233</span>     <span class="n">experimental_use_kahan_sum</span><span class="o">=</span><span class="n">experimental_use_kahan_sum</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">234</span>     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">parameters</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/mvn_linear_operator.py:205,</span> in <span class="ni">MultivariateNormalLinearOperator.__init__</span><span class="nt">(self, loc, scale, validate_args, allow_nan_stats, experimental_use_kahan_sum, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span> <span class="k">if</span> <span class="n">loc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>   <span class="n">bijector</span> <span class="o">=</span> <span class="n">shift_bijector</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">204</span>       <span class="n">shift</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)(</span><span class="n">bijector</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">205</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultivariateNormalLinearOperator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span>     <span class="c1"># TODO(b/137665504): Use batch-adding meta-distribution to set the batch</span>
<span class="g g-Whitespace">    </span><span class="mi">207</span>     <span class="c1"># shape instead of tf.zeros.</span>
<span class="g g-Whitespace">    </span><span class="mi">208</span>     <span class="c1"># We use `Sample` instead of `Independent` because `Independent`</span>
<span class="g g-Whitespace">    </span><span class="mi">209</span>     <span class="c1"># requires concatenating `batch_shape` and `event_shape`, which loses</span>
<span class="g g-Whitespace">    </span><span class="mi">210</span>     <span class="c1"># static `batch_shape` information when `event_shape` is not statically</span>
<span class="g g-Whitespace">    </span><span class="mi">211</span>     <span class="c1"># known.</span>
<span class="g g-Whitespace">    </span><span class="mi">212</span>     <span class="n">distribution</span><span class="o">=</span><span class="n">sample</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">213</span>         <span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span>             <span class="n">loc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span>             <span class="n">scale</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)),</span>
<span class="g g-Whitespace">    </span><span class="mi">216</span>         <span class="n">event_shape</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span>         <span class="n">experimental_use_kahan_sum</span><span class="o">=</span><span class="n">experimental_use_kahan_sum</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">218</span>     <span class="n">bijector</span><span class="o">=</span><span class="n">bijector</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">219</span>     <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">parameters</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/transformed_distribution.py:244,</span> in <span class="ni">_TransformedDistribution.__init__</span><span class="nt">(self, distribution, bijector, kwargs_split_fn, validate_args, parameters, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">238</span> <span class="bp">self</span><span class="o">.</span><span class="n">_zero</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;zero&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">240</span> <span class="c1"># We don&#39;t just want to check isinstance(JointDistribution) because</span>
<span class="g g-Whitespace">    </span><span class="mi">241</span> <span class="c1"># TransformedDistributions with multipart bijectors are effectively</span>
<span class="g g-Whitespace">    </span><span class="mi">242</span> <span class="c1"># joint but don&#39;t inherit from JD. The &#39;duck-type&#39; test is that</span>
<span class="g g-Whitespace">    </span><span class="mi">243</span> <span class="c1"># JDs have a structured dtype.</span>
<span class="ne">--&gt; </span><span class="mi">244</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">forward_dtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_joint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">is_nested</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">247</span> <span class="nb">super</span><span class="p">(</span><span class="n">_TransformedDistribution</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span>     <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span>     <span class="n">reparameterization_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">reparameterization_type</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span>     <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1705,</span> in <span class="ni">Bijector.forward_dtype</span><span class="nt">(self, dtype, name, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1701</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest_util</span><span class="o">.</span><span class="n">broadcast_structure</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1702</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1703</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1704</span>   <span class="c1"># Make sure inputs are compatible with statically-known dtype.</span>
<span class="ne">-&gt; </span><span class="mi">1705</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1706</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1707</span>       <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">dtype_util</span><span class="o">.</span><span class="n">convert_to_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1708</span>       <span class="n">nest_util</span><span class="o">.</span><span class="n">coerce_structure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1709</span>       <span class="n">check_types</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1711</span> <span class="n">output_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_dtype</span><span class="p">(</span><span class="n">input_dtype</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1712</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1713</span>   <span class="c1"># kwargs may alter dtypes themselves, but we currently require</span>
<span class="g g-Whitespace">   </span><span class="mi">1714</span>   <span class="c1"># structure to be statically known.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/python/internal/backend/jax/nest.py:324,</span> in <span class="ni">map_structure_up_to</span><span class="nt">(shallow_structure, func, *structures, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">323</span> <span class="k">def</span> <span class="nf">map_structure_up_to</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">324</span>   <span class="k">return</span> <span class="n">map_structure_with_tuple_paths_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">325</span>       <span class="n">shallow_structure</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">326</span>       <span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">),</span>  <span class="c1"># Discards path.</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>       <span class="o">*</span><span class="n">structures</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>       <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/python/internal/backend/jax/nest.py:353,</span> in <span class="ni">map_structure_with_tuple_paths_up_to</span><span class="nt">(shallow_structure, func, expand_composites, *structures, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">350</span> <span class="k">for</span> <span class="n">input_tree</span> <span class="ow">in</span> <span class="n">structures</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">351</span>   <span class="n">assert_shallow_structure</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">352</span>       <span class="n">shallow_structure</span><span class="p">,</span> <span class="n">input_tree</span><span class="p">,</span> <span class="n">check_types</span><span class="o">=</span><span class="n">check_types</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">353</span> <span class="k">return</span> <span class="n">dm_tree</span><span class="o">.</span><span class="n">map_structure_with_path_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">354</span>     <span class="n">shallow_structure</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tree/__init__.py:778,</span> in <span class="ni">map_structure_with_path_up_to</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">776</span> <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="g g-Whitespace">    </span><span class="mi">777</span> <span class="k">for</span> <span class="n">path_and_values</span> <span class="ow">in</span> <span class="n">_multiyield_flat_up_to</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">778</span>   <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">path_and_values</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">779</span> <span class="k">return</span> <span class="n">unflatten_as</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/python/internal/backend/jax/nest.py:326,</span> in <span class="ni">map_structure_up_to.&lt;locals&gt;.&lt;lambda&gt;</span><span class="nt">(_, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">323</span> <span class="k">def</span> <span class="nf">map_structure_up_to</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span>   <span class="k">return</span> <span class="n">map_structure_with_tuple_paths_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">325</span>       <span class="n">shallow_structure</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">326</span>       <span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">),</span>  <span class="c1"># Discards path.</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>       <span class="o">*</span><span class="n">structures</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>       <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1707,</span> in <span class="ni">Bijector.forward_dtype.&lt;locals&gt;.&lt;lambda&gt;</span><span class="nt">(x)</span>
<span class="g g-Whitespace">   </span><span class="mi">1701</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest_util</span><span class="o">.</span><span class="n">broadcast_structure</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1702</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1703</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1704</span>   <span class="c1"># Make sure inputs are compatible with statically-known dtype.</span>
<span class="g g-Whitespace">   </span><span class="mi">1705</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1706</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1707</span>       <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">dtype_util</span><span class="o">.</span><span class="n">convert_to_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1708</span>       <span class="n">nest_util</span><span class="o">.</span><span class="n">coerce_structure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1709</span>       <span class="n">check_types</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1711</span> <span class="n">output_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_dtype</span><span class="p">(</span><span class="n">input_dtype</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1712</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1713</span>   <span class="c1"># kwargs may alter dtypes themselves, but we currently require</span>
<span class="g g-Whitespace">   </span><span class="mi">1714</span>   <span class="c1"># structure to be statically known.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/internal/dtype_util.py:247,</span> in <span class="ni">convert_to_dtype</span><span class="nt">(tensor_or_dtype, dtype, dtype_hint)</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor_or_dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">246</span>   <span class="n">dt</span> <span class="o">=</span> <span class="n">base_dtype</span><span class="p">(</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">dtype_hint</span> <span class="ow">or</span> <span class="n">tensor_or_dtype</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">247</span> <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issctype</span><span class="p">(</span><span class="n">tensor_or_dtype</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span>   <span class="n">dt</span> <span class="o">=</span> <span class="n">base_dtype</span><span class="p">(</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">dtype_hint</span> <span class="ow">or</span> <span class="n">tensor_or_dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">250</span>   <span class="c1"># If this is a Python object, call `convert_to_tensor` and grab the dtype.</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span>   <span class="c1"># Note that this will add ops in graph-mode; we may want to consider</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span>   <span class="c1"># other ways to handle this case.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/numpy/__init__.py:397,</span> in <span class="ni">__getattr__</span><span class="nt">(attr)</span>
<span class="g g-Whitespace">    </span><span class="mi">394</span>     <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="n">__former_attrs__</span><span class="p">[</span><span class="n">attr</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">396</span> <span class="k">if</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">__expired_attributes__</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">397</span>     <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">398</span>         <span class="sa">f</span><span class="s2">&quot;`np.</span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">` was removed in the NumPy 2.0 release. &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">399</span>         <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">__expired_attributes__</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">400</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">402</span> <span class="k">if</span> <span class="n">attr</span> <span class="o">==</span> <span class="s2">&quot;chararray&quot;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">403</span>     <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">404</span>         <span class="s2">&quot;`np.chararray` is deprecated and will be removed from &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">405</span>         <span class="s2">&quot;the main namespace in the future. Use an array with a string &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">406</span>         <span class="s2">&quot;or bytes dtype instead.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="ne">AttributeError</span>: `np.issctype` was removed in the NumPy 2.0 release. Use `issubclass(rep, np.generic)` instead.
</pre></div>
</div>
</div>
</div>
</section>
<section id="ukf">
<h3>UKF<a class="headerlink" href="#ukf" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run CMGF-UKF and extract final estimates for moments</span>
<span class="n">ukf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_params</span><span class="p">,</span> <span class="n">UKFIntegrals</span><span class="p">(),</span> <span class="n">output</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">input_with_bias</span><span class="p">)</span>
<span class="n">ukf_means</span><span class="p">,</span> <span class="n">ukf_covs</span> <span class="o">=</span> <span class="n">ukf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">ukf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
<span class="n">w_ukf</span><span class="p">,</span> <span class="n">cov_ukf</span> <span class="o">=</span> <span class="n">ukf_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ukf_covs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">fig_adf</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Plot posterior predictive distribution</span>
<span class="n">Z_ukf</span> <span class="o">=</span> <span class="n">posterior_predictive_grid</span><span class="p">(</span><span class="n">input_with_bias_grid</span><span class="p">,</span> <span class="n">w_ukf</span><span class="p">,</span> <span class="n">cov_ukf</span><span class="p">)</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;CMGF-UKF Predictive Distribution&quot;</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">Z_ukf</span><span class="p">)</span>

<span class="n">plot_cmgf_post_laplace</span><span class="p">(</span><span class="n">ukf_means</span><span class="p">[::</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">//</span><span class="mi">100</span><span class="p">)],</span> <span class="n">ukf_covs</span><span class="p">[::</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">//</span><span class="mi">100</span><span class="p">)],</span> <span class="n">w_laplace</span><span class="p">,</span> <span class="n">lcolors</span><span class="p">,</span> <span class="n">filter_type</span><span class="o">=</span><span class="s2">&quot;CMGF-UKF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/8955901de20b6c1333f87bbb65be52453e72b9afa1c5439cdc0f1e9b629db273.png" src="../../_images/8955901de20b6c1333f87bbb65be52453e72b9afa1c5439cdc0f1e9b629db273.png" />
<img alt="../../_images/a36a2f23ba39152075ffddab0087f1fd772f04d70840b02bd06229a53b53c71d.png" src="../../_images/a36a2f23ba39152075ffddab0087f1fd772f04d70840b02bd06229a53b53c71d.png" />
<img alt="../../_images/56a1ddc5825e58855c6da07738c792fae9dc5e371c7d7e1dd2ebc573f5eec710.png" src="../../_images/56a1ddc5825e58855c6da07738c792fae9dc5e371c7d7e1dd2ebc573f5eec710.png" />
<img alt="../../_images/0367f6217309f582bdd4b450b08524632e933406040e04d52274c7861d1273f4.png" src="../../_images/0367f6217309f582bdd4b450b08524632e933406040e04d52274c7861d1273f4.png" />
</div>
</div>
</section>
<section id="ghkf">
<h3>GHKF<a class="headerlink" href="#ghkf" title="Link to this heading">#</a></h3>
<p>Gauss Hermite Kalman Filter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run CMGF-GHKF and extract final estimates for moments</span>
<span class="n">ghkf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_params</span><span class="p">,</span> <span class="n">GHKFIntegrals</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">output</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">input_with_bias</span><span class="p">)</span>
<span class="n">ghkf_means</span><span class="p">,</span> <span class="n">ghkf_covs</span> <span class="o">=</span> <span class="n">ghkf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">ghkf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
<span class="n">w_ghkf</span><span class="p">,</span> <span class="n">cov_ghkf</span> <span class="o">=</span> <span class="n">ghkf_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ghkf_covs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">fig_adf</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="c1"># Plot posterior predictive distribution</span>
<span class="n">Z_ghkf</span> <span class="o">=</span> <span class="n">posterior_predictive_grid</span><span class="p">(</span><span class="n">input_with_bias_grid</span><span class="p">,</span> <span class="n">w_ghkf</span><span class="p">,</span> <span class="n">cov_ghkf</span><span class="p">)</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;CMGF-GHKF Predictive Distribution&quot;</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">Z_ghkf</span><span class="p">)</span>

<span class="n">plot_cmgf_post_laplace</span><span class="p">(</span><span class="n">ghkf_means</span><span class="p">[::</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">//</span><span class="mi">100</span><span class="p">)],</span> <span class="n">ghkf_covs</span><span class="p">[::</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">//</span><span class="mi">100</span><span class="p">)],</span> <span class="n">w_laplace</span><span class="p">,</span> <span class="n">lcolors</span><span class="p">,</span> <span class="n">filter_type</span><span class="o">=</span><span class="s2">&quot;CMGF-GHKF&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/9f418186530bcc0ff063e45c5d650212b46248e8ae42eed6411ceda3147ca04a.png" src="../../_images/9f418186530bcc0ff063e45c5d650212b46248e8ae42eed6411ceda3147ca04a.png" />
<img alt="../../_images/498a8050693beb2d827fb1b4fbf6d8d5b23b55bc81ab2e92a57b706601661d37.png" src="../../_images/498a8050693beb2d827fb1b4fbf6d8d5b23b55bc81ab2e92a57b706601661d37.png" />
<img alt="../../_images/116def7858da920e0dbf9ec5c18306839fb1a77f386f1fbaa4411c50a96b335f.png" src="../../_images/116def7858da920e0dbf9ec5c18306839fb1a77f386f1fbaa4411c50a96b335f.png" />
<img alt="../../_images/09a78af058ce51b4a7b023733c0bbd35817314485bf20edc14562c69639e873c.png" src="../../_images/09a78af058ce51b4a7b023733c0bbd35817314485bf20edc14562c69639e873c.png" />
</div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../nonlinear_gaussian_ssm/ekf_mlp.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Online learning for an MLP using extended Kalman filtering</p>
      </div>
    </a>
    <a class="right-next"
       href="cmgf_mlp_classification_demo.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Online learning of an MLP Classifier using conditional moments Gaussian filter</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-and-plotting">Simulation and Plotting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laplace-estimate">Laplace Estimate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamical-model">Dynamical model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-inference">Online inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ekf">EKF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ukf">UKF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ghkf">GHKF</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Peter Chang, Giles Harper-Donnelly, Aleyna Kara, Xinglong Li, Scott Linderman, and Kevin Murphy
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2022, Peter Chang, Giles Harper-Donnelly, Aleyna Kara, Xinglong Li, Scott Linderman, and Kevin Murphy.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>