
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Online Logistic Regression using conditional moments Gaussian filter</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/generalized_gaussian_ssm/cmgf_logistic_regression_demo';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Online learning of an MLP Classifier using conditional moments Gaussian filter" href="cmgf_mlp_classification_demo.html" />
    <link rel="prev" title="Online learning for an MLP using extended Kalman filtering" href="../nonlinear_gaussian_ssm/ekf_mlp.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.gif" class="logo__image only-light" alt=" - Home"/>
    <script>document.write(`<img src="../../_static/logo.gif" class="logo__image only-dark" alt=" - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">HMMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hmm/casino_hmm_inference.html">Casino HMM: Inference (state estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/casino_hmm_learning.html">Casino HMM: Learning (parameter estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/gaussian_hmm.html">Gaussian HMM: Cross-validation and Model Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/autoregressive_hmm.html">Autoregressive (AR) HMM Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/custom_hmm.html">Creating Custom HMMs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Gaussian SSMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/kf_tracking.html">Tracking an object using the Kalman filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/kf_linreg.html">Online linear regression using Kalman filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_parallel_inference.html">Parallel filtering and smoothing in an LG-SSM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_learning.html">MAP parameter estimation for an LG-SSM using EM and SGD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_hmc.html">Bayesian parameter estimation for an LG-SSM using HMC</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Nonlinear Gaussian SSMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_ukf_spiral.html">Tracking a spiraling object using the extended / unscented Kalman filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_ukf_pendulum.html">Tracking a 1d pendulum using Extended / Unscented Kalman filter/ smoother</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_mlp.html">Online learning for an MLP using extended Kalman filtering</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generalized Gaussian SSMs</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Online Logistic Regression using conditional moments Gaussian filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cmgf_mlp_classification_demo.html">Online learning of an MLP Classifier using conditional moments Gaussian filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cmgf_poisson_demo.html">State Inference in a Poisson LDS using the Conditional Moments Gaussian Smoother</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../types.html">Terminology for types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">State Space Model (Base class)</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/probml/dynamax/main?urlpath=tree/docs/notebooks/generalized_gaussian_ssm/cmgf_logistic_regression_demo.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/probml/dynamax/blob/main/docs/notebooks/generalized_gaussian_ssm/cmgf_logistic_regression_demo.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/probml/dynamax" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Online Logistic Regression using conditional moments Gaussian filter</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-and-plotting">Simulation and Plotting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-posterior-predictive">Visualizing the posterior predictive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-inference-with-the-laplace-approximation">Offline inference with the Laplace approximation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-inference-with-cmgf">Online inference with CMGF</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-function-for-plotting">Helper function for plotting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up-the-cmgf-parameters">Set up the CMGF Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-cmgf-using-the-ekf-style-integral-approximations">Run the CMGF using the EKF-style integral approximations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-cmgf-using-the-ukf-style-integral-approximations">Run the CMGF using the UKF-style integral approximations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ghkf">GHKF</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="online-logistic-regression-using-conditional-moments-gaussian-filter">
<h1>Online Logistic Regression using conditional moments Gaussian filter<a class="headerlink" href="#online-logistic-regression-using-conditional-moments-gaussian-filter" title="Link to this heading">#</a></h1>
<p>This notebook shows how to do online (recursive) Bayesian inference of the weights of a logistic regression model using conditional moments Gaussian filter (CMGF). To do this, we treat the parameters of the model as the unknown hidden states.
We assume that these are approximately constant over time (we add a small amount of Gaussian drift, for numerical stability.)
The graphical model is shown below.</p>
<p><img alt="RLS" src="https://github.com/probml/dynamax/blob/main/docs/figures/rlsDgm.png?raw=true" /></p>
<p>The model has the following form</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\theta_t &amp;=  \theta_{t-1} + q_t, \; q_t \sim \mathrm{N}(0, 0.01 I)  \\
y_t &amp;\sim \mathrm{Bern}(\sigma(\theta_t^T x_t))
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma(a) = e^a /(1+e^a)\)</span> is the logistic (aka sigmoid) function.
This is a generalized Gaussian SSM, where the observation model is non-Gaussian.</p>
<p>We perform approximate inference using the conditional moments Gaussian filter (CMGF).
We approximate the relevant integrals using 3 different methods:</p>
<ol class="arabic simple">
<li><p>linearization (extended Kalman filter),</p></li>
<li><p>sigma point approximation (unscented kalman filter), and</p></li>
<li><p>Gauss hermite integration (order 5).
We compare results with the offline (batch) Laplace approximation, and see that GHKF converges fastest to the batch solution,
but is also slower.
For more details, see sec 8.7.7 of <a class="reference external" href="https://probml.github.io/pml-book/book2.html">Probabilistic Machine Learning: Advanced Topics</a>.</p></li>
</ol>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">dynamax</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;installing dynamax&#39;</span><span class="p">)</span>
    <span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">dynamax</span><span class="p">[</span><span class="n">notebooks</span><span class="p">]</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">dynamax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.random</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jr</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">jax.scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">minimize</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">dynamax.generalized_gaussian_ssm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParamsGGSSM</span><span class="p">,</span> <span class="n">EKFIntegrals</span><span class="p">,</span> <span class="n">UKFIntegrals</span><span class="p">,</span> <span class="n">GHKFIntegrals</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dynamax.generalized_gaussian_ssm</span><span class="w"> </span><span class="kn">import</span> <span class="n">conditional_moments_gaussian_filter</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="simulation-and-plotting">
<h2>Simulation and Plotting<a class="headerlink" href="#simulation-and-plotting" title="Link to this heading">#</a></h2>
<p>First, we generate a simple dataset for 2d binary classification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">generate_dataset</span><span class="p">(</span><span class="n">num_points</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">key0</span><span class="p">,</span> <span class="n">key1</span><span class="p">,</span> <span class="n">key2</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Generate standardized noisy inputs that correspond to output &#39;0&#39;</span>
    <span class="n">num_zero_points</span> <span class="o">=</span> <span class="n">num_points</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">zero_input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]</span> <span class="o">*</span> <span class="n">num_zero_points</span><span class="p">)</span>
    <span class="n">zero_input</span> <span class="o">+=</span> <span class="n">jr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key0</span><span class="p">,</span> <span class="p">(</span><span class="n">num_zero_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Generate standardized noisy inputs that correspond to output &#39;1&#39;</span>
    <span class="n">num_one_points</span> <span class="o">=</span> <span class="n">num_points</span> <span class="o">-</span> <span class="n">num_zero_points</span>
    <span class="n">one_input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]</span> <span class="o">*</span> <span class="n">num_one_points</span><span class="p">)</span>
    <span class="n">one_input</span> <span class="o">+=</span> <span class="n">jr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key1</span><span class="p">,</span> <span class="p">(</span><span class="n">num_one_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Stack the inputs and add bias term</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">zero_input</span><span class="p">,</span> <span class="n">one_input</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_points</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Generate binary output</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_zero_points</span><span class="p">)),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_one_points</span><span class="p">))])</span>

    <span class="c1"># Shuffle</span>
    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">key2</span><span class="p">,</span> <span class="n">num_points</span><span class="p">)</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at our binary data in 2d.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$y=0$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$y=0$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x_2$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;binary classification data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/636a258058f71bb1d5e15ddfe54e3ed66b030a426a39e00fb59ffd9cc5b85a9a.png" src="../../_images/636a258058f71bb1d5e15ddfe54e3ed66b030a426a39e00fb59ffd9cc5b85a9a.png" />
</div>
</div>
</section>
<section id="visualizing-the-posterior-predictive">
<h2>Visualizing the posterior predictive<a class="headerlink" href="#visualizing-the-posterior-predictive" title="Link to this heading">#</a></h2>
<p>Next, we define functions to compute and visualize the 2d posterior predictive distribution.
Let <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{n \times p}\)</span> denote the covariates of the training covariates (inputs) and <span class="math notranslate nohighlight">\(\mathbf{y} \in \{0,1\}^n\)</span> denote the training labels (outputs). The posterior predictive probability of a new label <span class="math notranslate nohighlight">\(y'\)</span> associated with a new covariate <span class="math notranslate nohighlight">\(x' \in \mathbb{R}^p\)</span> is,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\Pr(y'=1 \mid x', \mathbf{X}, \mathbf{y})
&amp;= \int \mathrm{Pr}(y'=1 \mid x', \theta) \, p(\theta \mid \mathbf{X}, \mathbf{y}) \, \mathrm{d} \theta \\
&amp;= \int \sigma(\theta^\top x') \, p(\theta \mid \mathbf{X}, \mathbf{y}) \, \mathrm{d} \theta \\
&amp;\approx \frac{1}{S} \sum_{s=1}^S \sigma( {\theta^{(s)}}^\top x')
\end{align*}\]</div>
<p>where</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\theta^{(s)} \stackrel{\mathsf{ind}}{\sim} p(\theta \mid \mathbf{X}, \mathbf{y}).
\end{align*}\]</div>
<p>In practice, we cannot compute the posterior distribution of <span class="math notranslate nohighlight">\(\theta\)</span> exactly, so we plug in a Gaussian approximation obtained with either the CMGF (for online infererence) or the Laplace approximation (for offline, full-batch inference).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_posterior_predictive</span><span class="p">(</span><span class="n">lim</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the posterior predictive distribution of the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lim : float</span>
<span class="sd">        evaluate a grid ranging from (-lim, lim) in all dimensions</span>
<span class="sd">    mean : array</span>
<span class="sd">        mean of the posterior distribution over weights</span>
<span class="sd">    cov : array</span>
<span class="sd">        covariance of the posterior distribution over weights</span>
<span class="sd">    n_samples : int</span>
<span class="sd">        number of samples to use to approximate the posterior predictive distribution</span>
<span class="sd">    key : int or jax.random.PRNGKey</span>
<span class="sd">        random key</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="c1"># Define grid</span>
    <span class="n">npts</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">lim</span><span class="p">,</span> <span class="n">lim</span><span class="p">,</span> <span class="n">npts</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">lim</span><span class="p">,</span> <span class="n">lim</span><span class="p">,</span> <span class="n">npts</span><span class="p">))</span>
    <span class="n">X_grid</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">])</span>
    <span class="n">X_grid_with_bias</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">npts</span><span class="p">,</span> <span class="n">npts</span><span class="p">)),</span> <span class="n">X_grid</span><span class="p">])</span>

    <span class="n">samples</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,))</span>
    <span class="n">E_y</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;mij,sm-&gt;sij&quot;</span><span class="p">,</span> <span class="n">X_grid_with_bias</span><span class="p">,</span> <span class="n">samples</span><span class="p">))</span>
    <span class="n">E_y</span> <span class="o">=</span> <span class="n">E_y</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_grid</span><span class="p">,</span> <span class="n">E_y</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_posterior_predictive</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                              <span class="n">w_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                              <span class="n">w_cov</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                              <span class="n">true_w</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span><span class="p">,</span> 
                              <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                              <span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot the posterior predictive distribution of the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array</span>
<span class="sd">        input data</span>
<span class="sd">    y : array</span>
<span class="sd">        labels</span>
<span class="sd">    w_mean : array</span>
<span class="sd">        mean of the posterior distribution over weights</span>
<span class="sd">    w_cov : array</span>
<span class="sd">        covariance of the posterior distribution over weights</span>
<span class="sd">    true_w : array</span>
<span class="sd">        true weights</span>
<span class="sd">    cmap : str</span>
<span class="sd">        colormap</span>
<span class="sd">    ax : matplotlib.axes.Axes</span>
<span class="sd">        axes to plot on</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">w_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">w_cov</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Compute and show the posterior predictive distribution</span>
        <span class="n">lim</span> <span class="o">=</span> <span class="mf">1.05</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="n">X_grid</span><span class="p">,</span> <span class="n">E_y</span> <span class="o">=</span> <span class="n">compute_posterior_predictive</span><span class="p">(</span><span class="n">lim</span><span class="p">,</span> <span class="n">w_mean</span><span class="p">,</span> <span class="n">w_cov</span><span class="p">)</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="o">*</span><span class="n">X_grid</span><span class="p">,</span> <span class="n">E_y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;posterior predictive probability&quot;</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    
    <span class="c1"># Scatter plot the data</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$y=0$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$y=1$&quot;</span><span class="p">)</span>

    <span class="c1"># Compute the true decision boundary</span>
    <span class="k">if</span> <span class="n">true_w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">X_grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="o">-</span><span class="n">true_w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">true_w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">true_w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">true_w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;true boundary&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$x_2$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="offline-inference-with-the-laplace-approximation">
<h2>Offline inference with the Laplace approximation<a class="headerlink" href="#offline-inference-with-the-laplace-approximation" title="Link to this heading">#</a></h2>
<p>We use the Laplace approximation to compute an approximate posterior given all the data (i.e., an offline estimate),</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
p(\theta \mid \mathbf{X}, \mathbf{y})
&amp;\approx 
\mathrm{N}(\theta \mid \mu, \Sigma)
\end{align*}\]</div>
<p>where</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mu &amp;= \arg \max_\theta \mathcal{L}(\theta) \\
\mathcal{L}(\theta) &amp;= \sum_{i=1}^n \log p(y_i \mid x_i, \theta) + \log p(\theta)
\end{align*}\]</div>
<p>is the <em>maximum a posteriori</em> (MAP) estimate of the parameters and</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\Sigma &amp;= - [\nabla^2 \mathcal{L}(\theta)|_{\theta = \mu}]^{-1}
\end{align*}\]</div>
<p>is the negative inverse Hessian around the MAP estimate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">log_joint</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">prior_var</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">log_prior</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">prior_var</span> <span class="o">*</span> <span class="n">w</span> <span class="o">@</span> <span class="n">w</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_prior</span> <span class="o">+</span> <span class="n">log_likelihood</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">laplace_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">prior_var</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">input_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Initial random guess</span>
    <span class="n">w0</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">input_dim</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">input_dim</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior_var</span><span class="p">)</span>
    
    <span class="c1"># Energy function to minimize</span>
    <span class="n">E</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="o">-</span><span class="n">log_joint</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">prior_var</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="c1"># Find the MAP estimate and the Hessian around that point</span>
    <span class="n">w_laplace</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">E</span><span class="p">,</span> <span class="n">w0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;BFGS&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">x</span>
    <span class="n">cov_laplace</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">E</span><span class="p">)(</span><span class="n">w_laplace</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">w_laplace</span><span class="p">,</span> <span class="n">cov_laplace</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute Laplace posterior</span>
<span class="n">prior_var</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">w_mean_laplace</span><span class="p">,</span> <span class="n">w_cov_laplace</span> <span class="o">=</span> <span class="n">laplace_inference</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">prior_var</span><span class="o">=</span><span class="n">prior_var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w_mean_laplace</span><span class="p">,</span> <span class="n">w_cov_laplace</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Posterior predictive with Laplace approximation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Posterior predictive with Laplace approximation&#39;)
</pre></div>
</div>
<img alt="../../_images/f4ad26c8f361cc057fc0d6c048c4d8c4245224522b14037e25fb8776c0a23e45.png" src="../../_images/f4ad26c8f361cc057fc0d6c048c4d8c4245224522b14037e25fb8776c0a23e45.png" />
</div>
</div>
</section>
<section id="online-inference-with-cmgf">
<h2>Online inference with CMGF<a class="headerlink" href="#online-inference-with-cmgf" title="Link to this heading">#</a></h2>
<p>Now, let’s use the conditional moments Gaussian filter (CMGF) to estimate the posterior in online fashion, one data point at a time. As described above, we formulate the online inference problem as filtering in a nonlinear Gaussian model where the latent states are the parameters of the model.</p>
<section id="helper-function-for-plotting">
<h3>Helper function for plotting<a class="headerlink" href="#helper-function-for-plotting" title="Link to this heading">#</a></h3>
<p>The function below plots the convergence of filtered estimates compared to the offline Laplace estimate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_online_inference</span><span class="p">(</span><span class="n">w_means</span><span class="p">,</span> 
                          <span class="n">w_covs</span><span class="p">,</span> 
                          <span class="n">w_mean_offline</span><span class="p">,</span>
                          <span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot the online inference of the weights.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    w_means : array</span>
<span class="sd">        means of the weights at each time step</span>
<span class="sd">    w_covs : array</span>
<span class="sd">        covariances of the weights at each time step</span>
<span class="sd">    w_mean_offline : array</span>
<span class="sd">        offline estimate of the weights</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_datapoints</span><span class="p">,</span> <span class="n">input_dim</span> <span class="o">=</span> <span class="n">w_means</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="n">input_dim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;Only works for 3D weights&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">w_stds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">)(</span><span class="n">w_covs</span><span class="p">))</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_datapoints</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">inds</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_datapoints</span><span class="p">,</span> <span class="n">step</span><span class="p">),</span> 
                            <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">n_datapoints</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])])</span>
    <span class="k">assert</span> <span class="n">w_stds</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_datapoints</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_dim</span><span class="p">):</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">ts</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">w_means</span><span class="p">[</span><span class="n">inds</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">w_stds</span><span class="p">[</span><span class="n">inds</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;online&quot;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">w_mean_offline</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;offline&quot;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">rf</span><span class="s2">&quot;$w_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">$&quot;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_datapoints</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;ordered sample number&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">input_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-up-the-cmgf-parameters">
<h3>Set up the CMGF Parameters<a class="headerlink" href="#set-up-the-cmgf-parameters" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">state_dim</span> <span class="o">=</span> <span class="n">input_dim</span> <span class="c1"># linear model</span>
<span class="n">sigmoid_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">w</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span>

<span class="c1"># Initial parameters for all CMGF methods</span>
<span class="n">initial_mean</span><span class="p">,</span> <span class="n">initial_covariance</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">state_dim</span><span class="p">),</span> <span class="n">prior_var</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">state_dim</span><span class="p">)</span>
<span class="n">dynamics_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">w</span>
<span class="n">dynamics_covariance</span> <span class="o">=</span> <span class="mf">1e-8</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">state_dim</span><span class="p">)</span>
<span class="n">emission_mean_function</span> <span class="o">=</span> <span class="n">sigmoid_fn</span>
<span class="n">emission_cov_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

<span class="n">cmgf_params</span> <span class="o">=</span> <span class="n">ParamsGGSSM</span><span class="p">(</span>
    <span class="n">initial_mean</span> <span class="o">=</span> <span class="n">initial_mean</span><span class="p">,</span>
    <span class="n">initial_covariance</span> <span class="o">=</span> <span class="n">initial_covariance</span><span class="p">,</span>
    <span class="n">dynamics_function</span> <span class="o">=</span> <span class="n">dynamics_function</span><span class="p">,</span>
    <span class="n">dynamics_covariance</span> <span class="o">=</span> <span class="n">dynamics_covariance</span><span class="p">,</span>
    <span class="n">emission_mean_function</span> <span class="o">=</span> <span class="n">emission_mean_function</span><span class="p">,</span>
    <span class="n">emission_cov_function</span> <span class="o">=</span> <span class="n">emission_cov_function</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-the-cmgf-using-the-ekf-style-integral-approximations">
<h3>Run the CMGF using the EKF-style integral approximations<a class="headerlink" href="#run-the-cmgf-using-the-ekf-style-integral-approximations" title="Link to this heading">#</a></h3>
<p>To run the CMGF, we also need to specify how we approximate the non-Gaussian integrals. First, we use an EKF-style approximation based on a first-order Taylor approximation of the nonlinear emission function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run CMGF-EKF and extract final estimates for moments</span>
<span class="n">ekf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_params</span><span class="p">,</span> <span class="n">EKFIntegrals</span><span class="p">(),</span> <span class="n">y</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
<span class="n">ekf_means</span><span class="p">,</span> <span class="n">ekf_covs</span> <span class="o">=</span> <span class="n">ekf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">ekf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot posterior predictive distribution</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ekf_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ekf_covs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Posterior Predictive with CMGF-EKF </span><span class="se">\n</span><span class="s2"> (after seeing all data points)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/aee761a61abfcaad72dd321eed44c3b9bf3f16ad61772af6dd1bf28ab1384580.png" src="../../_images/aee761a61abfcaad72dd321eed44c3b9bf3f16ad61772af6dd1bf28ab1384580.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plot_online_inference</span><span class="p">(</span><span class="n">ekf_means</span><span class="p">,</span> <span class="n">ekf_covs</span><span class="p">,</span> <span class="n">w_mean_laplace</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Online inference of weights with CMGF-EKF&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.05, &#39;Online inference of weights with CMGF-EKF&#39;)
</pre></div>
</div>
<img alt="../../_images/8c6dc63903c3580f65282ac4d19f9ffe8f71fd3bfa9cfc941e81b630a7736387.png" src="../../_images/8c6dc63903c3580f65282ac4d19f9ffe8f71fd3bfa9cfc941e81b630a7736387.png" />
</div>
</div>
</section>
<section id="run-the-cmgf-using-the-ukf-style-integral-approximations">
<h3>Run the CMGF using the UKF-style integral approximations<a class="headerlink" href="#run-the-cmgf-using-the-ukf-style-integral-approximations" title="Link to this heading">#</a></h3>
<p>Next we use a UKF-style approximation based on a sigma-point approximation of the nonlinear emission function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run CMGF-UKF and extract final estimates for moments</span>
<span class="n">ukf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_params</span><span class="p">,</span> <span class="n">UKFIntegrals</span><span class="p">(),</span> <span class="n">y</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
<span class="n">ukf_means</span><span class="p">,</span> <span class="n">ukf_covs</span> <span class="o">=</span> <span class="n">ukf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">ukf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot posterior predictive distribution</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ukf_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ukf_covs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Posterior Predictive with CMGF-UKF </span><span class="se">\n</span><span class="s2"> (after seeing all data points)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4060378aa91ea6d2b41b16d805194bd0beeb97c8d54ae21fbb17f969201db82f.png" src="../../_images/4060378aa91ea6d2b41b16d805194bd0beeb97c8d54ae21fbb17f969201db82f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plot_online_inference</span><span class="p">(</span><span class="n">ukf_means</span><span class="p">,</span> <span class="n">ukf_covs</span><span class="p">,</span> <span class="n">w_mean_laplace</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Online inference of weights with CMGF-UKF&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.05, &#39;Online inference of weights with CMGF-UKF&#39;)
</pre></div>
</div>
<img alt="../../_images/7694be2129396714593ba67f534dca07a4cf4a5c36f5290552bff6f4db0450d7.png" src="../../_images/7694be2129396714593ba67f534dca07a4cf4a5c36f5290552bff6f4db0450d7.png" />
</div>
</div>
</section>
<section id="ghkf">
<h3>GHKF<a class="headerlink" href="#ghkf" title="Link to this heading">#</a></h3>
<p>Finally, run the CMGF using Gauss-Hermite quadrature to approximate the integrals.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run CMGF-GHKF and extract final estimates for moments</span>
<span class="n">ghkf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_params</span><span class="p">,</span> <span class="n">GHKFIntegrals</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
<span class="n">ghkf_means</span><span class="p">,</span> <span class="n">ghkf_covs</span> <span class="o">=</span> <span class="n">ghkf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">ghkf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot posterior predictive distribution</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ghkf_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">ghkf_covs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Posterior Predictive with CMGF-GHKF </span><span class="se">\n</span><span class="s2"> (after seeing all data points)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/133a280ecb97e9c19b0399971975bc79f9e4805c6e1ef4cca2064cdce834b05f.png" src="../../_images/133a280ecb97e9c19b0399971975bc79f9e4805c6e1ef4cca2064cdce834b05f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plot_online_inference</span><span class="p">(</span><span class="n">ghkf_means</span><span class="p">,</span> <span class="n">ghkf_covs</span><span class="p">,</span> <span class="n">w_mean_laplace</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Online inference of weights with CMGF-GHKF&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.05, &#39;Online inference of weights with CMGF-GHKF&#39;)
</pre></div>
</div>
<img alt="../../_images/01955bbde5d6b29ff15ef5c33a40d0465d42488221629690f20184a6b1e4a0ab.png" src="../../_images/01955bbde5d6b29ff15ef5c33a40d0465d42488221629690f20184a6b1e4a0ab.png" />
</div>
</div>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>This notebook demonstrates how to use a conditional moments Gaussian filter (CMGF) to perform online approximate inference of the weights of a logistic regression model. You can choose different methods of approximating the integrals inside the CMGF, and here it looks like the Gauss-Hermite quadrature rule yields a filter that best approximates the offline posterior estimate.</p>
<p>In all cases, it appears the online estimates slightly underestimate the magnitude of the true weights. This bias likely arises from an accumulation of errors since the online algorithms iteratively approximate the filtering distributions as Gaussian at each time point, whereas the Laplace approximation forms a Gaussian approximation to the full posterior. It appears that the UKF and Gauss-Hermite integral approximations are slightly better than the EKF in this regard.</p>
<p>Overall, this notebook shows how straightforward it is to perform these challenging inference tasks using Dynamax!</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../nonlinear_gaussian_ssm/ekf_mlp.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Online learning for an MLP using extended Kalman filtering</p>
      </div>
    </a>
    <a class="right-next"
       href="cmgf_mlp_classification_demo.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Online learning of an MLP Classifier using conditional moments Gaussian filter</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-and-plotting">Simulation and Plotting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-posterior-predictive">Visualizing the posterior predictive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-inference-with-the-laplace-approximation">Offline inference with the Laplace approximation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-inference-with-cmgf">Online inference with CMGF</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-function-for-plotting">Helper function for plotting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up-the-cmgf-parameters">Set up the CMGF Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-cmgf-using-the-ekf-style-integral-approximations">Run the CMGF using the EKF-style integral approximations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-cmgf-using-the-ukf-style-integral-approximations">Run the CMGF using the UKF-style integral approximations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ghkf">GHKF</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Peter Chang, Giles Harper-Donnelly, Aleyna Kara, Xinglong Li, Scott Linderman, and Kevin Murphy
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022, Peter Chang, Giles Harper-Donnelly, Aleyna Kara, Xinglong Li, Scott Linderman, and Kevin Murphy.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>