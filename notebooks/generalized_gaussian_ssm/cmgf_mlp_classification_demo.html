
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Online learning of an MLP Classifier using conditional moments Gaussian filter</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/generalized_gaussian_ssm/cmgf_mlp_classification_demo';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Fitting an LDS with Poisson Likelihood using conditional moments Gaussian filter" href="cmgf_poisson_demo.html" />
    <link rel="prev" title="Online Logistic Regression using conditional moments Gaussian filter" href="cmgf_logistic_regression_demo.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.gif" class="logo__image only-light" alt=" - Home"/>
    <script>document.write(`<img src="../../_static/logo.gif" class="logo__image only-dark" alt=" - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">HMMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hmm/casino_hmm_inference.html">Casino HMM: Inference (state estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/casino_hmm_learning.html">Casino HMM: Learning (parameter estimation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/gaussian_hmm.html">Gaussian HMM: Cross-validation and Model Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm/autoregressive_hmm.html">Autoregressive (AR) HMM Demo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Gaussian SSMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/kf_tracking.html">Tracking an object using the Kalman filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/kf_linreg.html">Online linear regression using Kalman filtering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_parallel_inference.html">Parallel filtering and smoothing in an LG-SSM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_learning.html">MAP parameter estimation for an LG-SSM using EM and SGD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_gaussian_ssm/lgssm_hmc.html">Bayesian parameter estimation for an LG-SSM using HMC</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Nonlinear Gaussian SSMs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_ukf_spiral.html">Tracking a spiraling object using the extended / unscented Kalman filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_ukf_pendulum.html">Tracking a 1d pendulum using Extended / Unscented Kalman filter/ smoother</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nonlinear_gaussian_ssm/ekf_mlp.html">Online learning for an MLP using extended Kalman filtering</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Generalized Gaussian SSMs</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="cmgf_logistic_regression_demo.html">Online Logistic Regression using conditional moments Gaussian filter</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Online learning of an MLP Classifier using conditional moments Gaussian filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="cmgf_poisson_demo.html">Fitting an LDS with Poisson Likelihood using conditional moments Gaussian filter</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../types.html">Terminology for types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">State Space Model (Base class)</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/probml/dynamax/main?urlpath=tree/docs/notebooks/generalized_gaussian_ssm/cmgf_mlp_classification_demo.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/probml/dynamax/blob/main/docs/notebooks/generalized_gaussian_ssm/cmgf_mlp_classification_demo.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/probml/dynamax" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Online learning of an MLP Classifier using conditional moments Gaussian filter</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-data">Create data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plotting-code">Plotting code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-mlp">Define MLP</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-training-using-cmgf-ekf">Online Training Using CMGF-EKF</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="online-learning-of-an-mlp-classifier-using-conditional-moments-gaussian-filter">
<h1>Online learning of an MLP Classifier using conditional moments Gaussian filter<a class="headerlink" href="#online-learning-of-an-mlp-classifier-using-conditional-moments-gaussian-filter" title="Link to this heading">#</a></h1>
<p>Online training of an multilayer perceptron (MLP) classifier using conditional moments Gaussian filter (CMGF).</p>
<p>We perform sequential (recursive) Bayesian inference for the parameters of a binary MLP classifier.
To do this, we treat the parameters of the model as the unknown hidden states.
We assume that these are approximately constant over time (we add a small amount of Gaussian drift,
for numerical stability.)
The graphical model is shown below.</p>
<p><img alt="RLS" src="https://github.com/probml/dynamax/blob/main/docs/figures/rlsDgm.png?raw=true" /></p>
<p>The model has the following form</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\theta_t &amp;=  \theta_{t-1} + q_t, \; q_t \sim N(0, 0.01 I)  \\
y_t &amp;\sim Ber(\sigma(h(x_t, \theta_t))
\end{align*}\]</div>
<p>This is a generalized Gaussian SSM, where the observation model is non-linear and non-Gaussian.</p>
<p>To perform approximate inference, using the conditional moments Gaussian filter (CMGF).
We approximate the relevant integrals using the extended Kalman filter.
For more details, see sec 8.7.7 of <a class="reference external" href="https://probml.github.io/pml-book/book2.html">Probabilistic Machine Learning: Advanced Topics</a>.</p>
<p>Video of training: https://gist.github.com/petergchang/9441b853b889e0b47d0622da8f7fe2f6</p>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dynamax</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;installing dynamax&#39;</span><span class="p">)</span>
    <span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">dynamax</span><span class="p">[</span><span class="n">notebooks</span><span class="p">]</span>
    <span class="kn">import</span> <span class="nn">dynamax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dynamax.generalized_gaussian_ssm</span> <span class="kn">import</span> <span class="n">ParamsGGSSM</span><span class="p">,</span> <span class="n">EKFIntegrals</span>
<span class="kn">from</span> <span class="nn">dynamax.generalized_gaussian_ssm</span> <span class="kn">import</span> <span class="n">conditional_moments_gaussian_filter</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">flax.linen</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;installing flax&#39;</span><span class="p">)</span>
    <span class="o">%</span><span class="k">pip</span> install -qq flax
<span class="kn">import</span> <span class="nn">flax.linen</span> <span class="k">as</span> <span class="nn">nn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax.random</span> <span class="k">as</span> <span class="nn">jr</span>
<span class="kn">from</span> <span class="nn">jax.flatten_util</span> <span class="kn">import</span> <span class="n">ravel_pytree</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Helper function that visualizes 2d posterior predictive distribution</span>
<span class="k">def</span> <span class="nf">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">Xspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Zspace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">rainbow</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">Xspace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Zspace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">Xspace</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="p">(</span><span class="n">Zspace</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="n">y</span> <span class="k">else</span> <span class="s1">&#39;blue&#39;</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="create-data">
<h2>Create data<a class="headerlink" href="#create-data" title="Link to this heading">#</a></h2>
<p>First, we generate a binary spiral data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate spiral dataset</span>
<span class="c1"># Adapted from https://gist.github.com/45deg/e731d9e7f478de134def5668324c44c5</span>
<span class="k">def</span> <span class="nf">generate_spiral_dataset</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_per_class</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">zero_var</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">one_var</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">key1</span><span class="p">,</span> <span class="n">key2</span><span class="p">,</span> <span class="n">key3</span><span class="p">,</span> <span class="n">key4</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="n">theta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">jr</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_per_class</span><span class="p">,)))</span> <span class="o">*</span> <span class="mi">2</span><span class="o">*</span><span class="n">jnp</span><span class="o">.</span><span class="n">pi</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">theta</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span>
    <span class="n">generate_data</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">r</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">*</span><span class="n">r</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

    <span class="c1"># Data for output zero</span>
    <span class="n">zero_input</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="n">zero_var</span> <span class="o">*</span> <span class="n">jr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_per_class</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">zero_output</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_per_class</span><span class="p">,</span> <span class="mi">1</span><span class="p">,))</span>

    <span class="c1"># Data for output one</span>
    <span class="n">one_input</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="o">-</span><span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="n">one_var</span> <span class="o">*</span> <span class="n">jr</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key3</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_per_class</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">one_output</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_per_class</span><span class="p">,</span> <span class="mi">1</span><span class="p">,))</span>

    <span class="c1"># Stack the inputs and standardize</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">zero_input</span><span class="p">,</span> <span class="n">one_input</span><span class="p">])</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="p">(</span><span class="nb">input</span> <span class="o">-</span> <span class="nb">input</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="nb">input</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Generate binary output</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_per_class</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_per_class</span><span class="p">)])</span>

    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">key4</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_per_class</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">return</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate data</span>
<span class="nb">input</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">generate_spiral_dataset</span><span class="p">()</span>

<span class="c1"># Plot data</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Spiral-shaped binary classification data&quot;</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">title</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/fbb8fa56899509f37d3fb9a4dd8be26f602287d4d503e16b2cc0ba0188df3203.png" src="../../_images/fbb8fa56899509f37d3fb9a4dd8be26f602287d4d503e16b2cc0ba0188df3203.png" />
</div>
</div>
</section>
<section id="plotting-code">
<h2>Plotting code<a class="headerlink" href="#plotting-code" title="Link to this heading">#</a></h2>
<p>Next, let us define a grid on which we compute the predictive distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define grid limits</span>
<span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.1</span>
<span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span>

<span class="c1"># Define grid</span>
<span class="n">step</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">x_grid</span><span class="p">,</span> <span class="n">y_grid</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="n">xmin</span><span class="p">:</span><span class="n">xmax</span><span class="p">:</span><span class="n">step</span><span class="p">],</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="n">ymin</span><span class="p">:</span><span class="n">ymax</span><span class="p">:</span><span class="n">step</span><span class="p">])</span>
<span class="n">input_grid</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_grid</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">y_grid</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="kc">None</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we define a function to that returns the posterior predictive probability for each point in grid.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># &#39;binary=True&#39; indicates rounding probabilities to binary outputs</span>
<span class="k">def</span> <span class="nf">posterior_predictive_grid</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">apply</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">inferred_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">apply</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">fn_vec</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">inferred_fn</span><span class="p">,</span> <span class="n">signature</span><span class="o">=</span><span class="s1">&#39;(2)-&gt;(3)&#39;</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">fn_vec</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">binary</span><span class="p">:</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">rint</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Z</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-mlp">
<h2>Define MLP<a class="headerlink" href="#define-mlp" title="Link to this heading">#</a></h2>
<p>Finally, we define a generic MLP class that uses a sigmoid activation function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">features</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>

    <span class="nd">@nn</span><span class="o">.</span><span class="n">compact</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">feat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">feat</span><span class="p">)(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_mlp_flattened_params</span><span class="p">(</span><span class="n">model_dims</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="c1"># Define MLP model</span>
    <span class="n">input_dim</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">model_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">model_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">input_dim</span><span class="p">,))</span>

    <span class="c1"># Initialize parameters using dummy input</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">)</span>
    <span class="n">flat_params</span><span class="p">,</span> <span class="n">unflatten_fn</span> <span class="o">=</span> <span class="n">ravel_pytree</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="c1"># Define apply function</span>
    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="n">flat_params</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">unflatten_fn</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">unflatten_fn</span><span class="p">(</span><span class="n">flat_params</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="n">apply_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">apply</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">unflatten_fn</span><span class="o">=</span><span class="n">unflatten_fn</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">flat_params</span><span class="p">,</span> <span class="n">unflatten_fn</span><span class="p">,</span> <span class="n">apply_fn</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="online-training-using-cmgf-ekf">
<h2>Online Training Using CMGF-EKF<a class="headerlink" href="#online-training-using-cmgf-ekf" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define MLP architecture</span>
<span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">,</span> <span class="n">output_dim</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="mi">1</span>
<span class="n">model_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_dim</span><span class="p">,</span> <span class="o">*</span><span class="n">hidden_dims</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">]</span>
<span class="n">_</span><span class="p">,</span> <span class="n">flat_params</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">apply_fn</span> <span class="o">=</span> <span class="n">get_mlp_flattened_params</span><span class="p">(</span><span class="n">model_dims</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some model parameters and helper function</span>
<span class="n">state_dim</span><span class="p">,</span> <span class="n">emission_dim</span> <span class="o">=</span> <span class="n">flat_params</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">output_dim</span>
<span class="n">sigmoid_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">apply_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

<span class="c1"># Run CMGF-EKF to train the MLP Classifier</span>
<span class="n">cmgf_ekf_params</span> <span class="o">=</span> <span class="n">ParamsGGSSM</span><span class="p">(</span>
    <span class="n">initial_mean</span><span class="o">=</span><span class="n">flat_params</span><span class="p">,</span>
    <span class="n">initial_covariance</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">state_dim</span><span class="p">),</span>
    <span class="n">dynamics_function</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span>
    <span class="n">dynamics_covariance</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">state_dim</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">emission_mean_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
    <span class="n">emission_cov_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">cmgf_ekf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_ekf_params</span><span class="p">,</span> <span class="n">EKFIntegrals</span><span class="p">(),</span> <span class="n">output</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># Extract history of filtered weight values</span>
<span class="n">w_means</span><span class="p">,</span> <span class="n">w_covs</span> <span class="o">=</span> <span class="n">cmgf_ekf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">cmgf_ekf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="n">line</span> <span class="mi">14</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># Run CMGF-EKF to train the MLP Classifier</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">cmgf_ekf_params</span> <span class="o">=</span> <span class="n">ParamsGGSSM</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>     <span class="n">initial_mean</span><span class="o">=</span><span class="n">flat_params</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>     <span class="n">initial_covariance</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">state_dim</span><span class="p">),</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>     <span class="n">emission_cov_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_fn</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">14</span> <span class="n">cmgf_ekf_post</span> <span class="o">=</span> <span class="n">conditional_moments_gaussian_filter</span><span class="p">(</span><span class="n">cmgf_ekf_params</span><span class="p">,</span> <span class="n">EKFIntegrals</span><span class="p">(),</span> <span class="n">output</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="c1"># Extract history of filtered weight values</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="n">w_means</span><span class="p">,</span> <span class="n">w_covs</span> <span class="o">=</span> <span class="n">cmgf_ekf_post</span><span class="o">.</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">cmgf_ekf_post</span><span class="o">.</span><span class="n">filtered_covariances</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:258,</span> in <span class="ni">conditional_moments_gaussian_filter</span><span class="nt">(model_params, inf_params, emissions, num_iter, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span> <span class="c1"># Run the general linearization filter</span>
<span class="g g-Whitespace">    </span><span class="mi">257</span> <span class="n">carry</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">model_params</span><span class="o">.</span><span class="n">initial_mean</span><span class="p">,</span> <span class="n">model_params</span><span class="o">.</span><span class="n">initial_covariance</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">258</span> <span class="p">(</span><span class="n">ll</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="p">(</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">filtered_covs</span><span class="p">)</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">_step</span><span class="p">,</span> <span class="n">carry</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_timesteps</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">259</span> <span class="k">return</span> <span class="n">PosteriorGSSMFiltered</span><span class="p">(</span><span class="n">marginal_loglik</span><span class="o">=</span><span class="n">ll</span><span class="p">,</span> <span class="n">filtered_means</span><span class="o">=</span><span class="n">filtered_means</span><span class="p">,</span> <span class="n">filtered_covariances</span><span class="o">=</span><span class="n">filtered_covs</span><span class="p">)</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">9</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:248,</span> in <span class="ni">conditional_moments_gaussian_filter.&lt;locals&gt;._step</span><span class="nt">(carry, t)</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span> <span class="n">y</span> <span class="o">=</span> <span class="n">emissions</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">247</span> <span class="c1"># Condition on the emission</span>
<span class="ne">--&gt; </span><span class="mi">248</span> <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">filtered_mean</span><span class="p">,</span> <span class="n">filtered_cov</span> <span class="o">=</span> <span class="n">_condition_on</span><span class="p">(</span><span class="n">pred_mean</span><span class="p">,</span> <span class="n">pred_cov</span><span class="p">,</span> <span class="n">m_Y</span><span class="p">,</span> <span class="n">Cov_Y</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">g_ev</span><span class="p">,</span> <span class="n">g_cov</span><span class="p">,</span> <span class="n">num_iter</span><span class="p">,</span> <span class="n">emission_dist</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="n">ll</span> <span class="o">+=</span> <span class="n">log_likelihood</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span> <span class="c1"># Predict the next state</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:171,</span> in <span class="ni">_condition_on</span><span class="nt">(m, P, y_cond_mean, y_cond_cov, u, y, g_ev, g_cov, num_iter, emission_dist)</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span> <span class="c1"># Iterate re-linearization over posterior mean and covariance</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span> <span class="n">carry</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">171</span> <span class="p">(</span><span class="n">mu_cond</span><span class="p">,</span> <span class="n">Sigma_cond</span><span class="p">),</span> <span class="n">lls</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">_step</span><span class="p">,</span> <span class="n">carry</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_iter</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span> <span class="k">return</span> <span class="n">lls</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mu_cond</span><span class="p">,</span> <span class="n">Sigma_cond</span>

    <span class="p">[</span><span class="o">...</span> <span class="n">skipping</span> <span class="n">hidden</span> <span class="mi">9</span> <span class="n">frame</span><span class="p">]</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/inference.py:162,</span> in <span class="ni">_condition_on.&lt;locals&gt;._step</span><span class="nt">(carry, _)</span>
<span class="g g-Whitespace">    </span><span class="mi">160</span> <span class="n">yhat</span> <span class="o">=</span> <span class="n">g_ev</span><span class="p">(</span><span class="n">m_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">161</span> <span class="n">S</span> <span class="o">=</span> <span class="n">g_ev</span><span class="p">(</span><span class="n">Cov_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span> <span class="o">+</span> <span class="n">g_cov</span><span class="p">(</span><span class="n">m_Y</span><span class="p">,</span> <span class="n">m_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">162</span> <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">emission_dist</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span> <span class="n">C</span> <span class="o">=</span> <span class="n">g_cov</span><span class="p">(</span><span class="n">identity_fn</span><span class="p">,</span> <span class="n">m_Y</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_cov</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span> <span class="n">K</span> <span class="o">=</span> <span class="n">psd_solve</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="nn">File ~/work/dynamax/dynamax/dynamax/generalized_gaussian_ssm/models.py:52,</span> in <span class="ni">ParamsGGSSM.&lt;lambda&gt;</span><span class="nt">(mean, cov)</span>
<span class="g g-Whitespace">     </span><span class="mi">50</span> <span class="n">emission_mean_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">FnStateToEmission</span><span class="p">,</span> <span class="n">FnStateAndInputToEmission</span><span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span> <span class="n">emission_cov_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">FnStateToEmission2</span><span class="p">,</span> <span class="n">FnStateAndInputToEmission2</span><span class="p">]</span>
<span class="ne">---&gt; </span><span class="mi">52</span> <span class="n">emission_dist</span><span class="p">:</span> <span class="n">EmissionDistFn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">:</span> <span class="n">MVN</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/mvn_full_covariance.py:191,</span> in <span class="ni">MultivariateNormalFullCovariance.__init__</span><span class="nt">(self, loc, covariance_matrix, validate_args, allow_nan_stats, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">185</span>       <span class="c1"># No need to validate that covariance_matrix is non-singular.</span>
<span class="g g-Whitespace">    </span><span class="mi">186</span>       <span class="c1"># LinearOperatorLowerTriangular has an assert_non_singular method that</span>
<span class="g g-Whitespace">    </span><span class="mi">187</span>       <span class="c1"># is called by the Bijector.</span>
<span class="g g-Whitespace">    </span><span class="mi">188</span>       <span class="c1"># However, cholesky() ignores the upper triangular part, so we do need</span>
<span class="g g-Whitespace">    </span><span class="mi">189</span>       <span class="c1"># to separately assert symmetric.</span>
<span class="g g-Whitespace">    </span><span class="mi">190</span>       <span class="n">scale_tril</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">covariance_matrix</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">191</span>     <span class="nb">super</span><span class="p">(</span><span class="n">MultivariateNormalFullCovariance</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">192</span>         <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">193</span>         <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale_tril</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">194</span>         <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span>         <span class="n">allow_nan_stats</span><span class="o">=</span><span class="n">allow_nan_stats</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">196</span>         <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">197</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">parameters</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/mvn_tril.py:228,</span> in <span class="ni">MultivariateNormalTriL.__init__</span><span class="nt">(self, loc, scale_tril, validate_args, allow_nan_stats, experimental_use_kahan_sum, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span>   <span class="n">linop_cls</span> <span class="o">=</span> <span class="p">(</span><span class="n">KahanLogDetLinOpTriL</span> <span class="k">if</span> <span class="n">experimental_use_kahan_sum</span> <span class="k">else</span>
<span class="g g-Whitespace">    </span><span class="mi">222</span>                <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorLowerTriangular</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">223</span>   <span class="n">scale</span> <span class="o">=</span> <span class="n">linop_cls</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">224</span>       <span class="n">scale_tril</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">225</span>       <span class="n">is_non_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">226</span>       <span class="n">is_self_adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">227</span>       <span class="n">is_positive_definite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">228</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultivariateNormalTriL</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">229</span>     <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span>     <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">232</span>     <span class="n">allow_nan_stats</span><span class="o">=</span><span class="n">allow_nan_stats</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">233</span>     <span class="n">experimental_use_kahan_sum</span><span class="o">=</span><span class="n">experimental_use_kahan_sum</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">234</span>     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">parameters</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/mvn_linear_operator.py:205,</span> in <span class="ni">MultivariateNormalLinearOperator.__init__</span><span class="nt">(self, loc, scale, validate_args, allow_nan_stats, experimental_use_kahan_sum, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span> <span class="k">if</span> <span class="n">loc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>   <span class="n">bijector</span> <span class="o">=</span> <span class="n">shift_bijector</span><span class="o">.</span><span class="n">Shift</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">204</span>       <span class="n">shift</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">)(</span><span class="n">bijector</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">205</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultivariateNormalLinearOperator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span>     <span class="c1"># TODO(b/137665504): Use batch-adding meta-distribution to set the batch</span>
<span class="g g-Whitespace">    </span><span class="mi">207</span>     <span class="c1"># shape instead of tf.zeros.</span>
<span class="g g-Whitespace">    </span><span class="mi">208</span>     <span class="c1"># We use `Sample` instead of `Independent` because `Independent`</span>
<span class="g g-Whitespace">    </span><span class="mi">209</span>     <span class="c1"># requires concatenating `batch_shape` and `event_shape`, which loses</span>
<span class="g g-Whitespace">    </span><span class="mi">210</span>     <span class="c1"># static `batch_shape` information when `event_shape` is not statically</span>
<span class="g g-Whitespace">    </span><span class="mi">211</span>     <span class="c1"># known.</span>
<span class="g g-Whitespace">    </span><span class="mi">212</span>     <span class="n">distribution</span><span class="o">=</span><span class="n">sample</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">213</span>         <span class="n">normal</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span>             <span class="n">loc</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span>             <span class="n">scale</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)),</span>
<span class="g g-Whitespace">    </span><span class="mi">216</span>         <span class="n">event_shape</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span>         <span class="n">experimental_use_kahan_sum</span><span class="o">=</span><span class="n">experimental_use_kahan_sum</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">218</span>     <span class="n">bijector</span><span class="o">=</span><span class="n">bijector</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">219</span>     <span class="n">validate_args</span><span class="o">=</span><span class="n">validate_args</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">parameters</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/decorator.py:232,</span> in <span class="ni">decorate.&lt;locals&gt;.fun</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">kwsyntax</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kw</span> <span class="o">=</span> <span class="n">fix</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">232</span> <span class="k">return</span> <span class="n">caller</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="p">(</span><span class="n">extras</span> <span class="o">+</span> <span class="n">args</span><span class="p">),</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/distribution.py:342,</span> in <span class="ni">_DistributionMeta.__new__.&lt;locals&gt;.wrapped_init</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span> <span class="c1"># Note: if we ever want to have things set in `self` before `__init__` is</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span> <span class="c1"># called, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">--&gt; </span><span class="mi">342</span> <span class="n">default_init</span><span class="p">(</span><span class="n">self_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span> <span class="c1"># Note: if we ever want to override things set in `self` by subclass</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span> <span class="c1"># `__init__`, here is the place to do it.</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span> <span class="k">if</span> <span class="n">self_</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>   <span class="c1"># We prefer subclasses will set `parameters = dict(locals())` because</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>   <span class="c1"># this has nearly zero overhead. However, failing to do this, we will</span>
<span class="g g-Whitespace">    </span><span class="mi">348</span>   <span class="c1"># resolve the input arguments dynamically and only when needed.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/distributions/transformed_distribution.py:244,</span> in <span class="ni">_TransformedDistribution.__init__</span><span class="nt">(self, distribution, bijector, kwargs_split_fn, validate_args, parameters, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">238</span> <span class="bp">self</span><span class="o">.</span><span class="n">_zero</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;zero&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">240</span> <span class="c1"># We don&#39;t just want to check isinstance(JointDistribution) because</span>
<span class="g g-Whitespace">    </span><span class="mi">241</span> <span class="c1"># TransformedDistributions with multipart bijectors are effectively</span>
<span class="g g-Whitespace">    </span><span class="mi">242</span> <span class="c1"># joint but don&#39;t inherit from JD. The &#39;duck-type&#39; test is that</span>
<span class="g g-Whitespace">    </span><span class="mi">243</span> <span class="c1"># JDs have a structured dtype.</span>
<span class="ne">--&gt; </span><span class="mi">244</span> <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bijector</span><span class="o">.</span><span class="n">forward_dtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_joint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">is_nested</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">247</span> <span class="nb">super</span><span class="p">(</span><span class="n">_TransformedDistribution</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span>     <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span>     <span class="n">reparameterization_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution</span><span class="o">.</span><span class="n">reparameterization_type</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span>     <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1705,</span> in <span class="ni">Bijector.forward_dtype</span><span class="nt">(self, dtype, name, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1701</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest_util</span><span class="o">.</span><span class="n">broadcast_structure</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1702</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1703</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1704</span>   <span class="c1"># Make sure inputs are compatible with statically-known dtype.</span>
<span class="ne">-&gt; </span><span class="mi">1705</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1706</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1707</span>       <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">dtype_util</span><span class="o">.</span><span class="n">convert_to_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1708</span>       <span class="n">nest_util</span><span class="o">.</span><span class="n">coerce_structure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1709</span>       <span class="n">check_types</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1711</span> <span class="n">output_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_dtype</span><span class="p">(</span><span class="n">input_dtype</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1712</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1713</span>   <span class="c1"># kwargs may alter dtypes themselves, but we currently require</span>
<span class="g g-Whitespace">   </span><span class="mi">1714</span>   <span class="c1"># structure to be statically known.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/python/internal/backend/jax/nest.py:324,</span> in <span class="ni">map_structure_up_to</span><span class="nt">(shallow_structure, func, *structures, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">323</span> <span class="k">def</span> <span class="nf">map_structure_up_to</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">324</span>   <span class="k">return</span> <span class="n">map_structure_with_tuple_paths_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">325</span>       <span class="n">shallow_structure</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">326</span>       <span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">),</span>  <span class="c1"># Discards path.</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>       <span class="o">*</span><span class="n">structures</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>       <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/python/internal/backend/jax/nest.py:353,</span> in <span class="ni">map_structure_with_tuple_paths_up_to</span><span class="nt">(shallow_structure, func, expand_composites, *structures, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">350</span> <span class="k">for</span> <span class="n">input_tree</span> <span class="ow">in</span> <span class="n">structures</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">351</span>   <span class="n">assert_shallow_structure</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">352</span>       <span class="n">shallow_structure</span><span class="p">,</span> <span class="n">input_tree</span><span class="p">,</span> <span class="n">check_types</span><span class="o">=</span><span class="n">check_types</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">353</span> <span class="k">return</span> <span class="n">dm_tree</span><span class="o">.</span><span class="n">map_structure_with_path_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">354</span>     <span class="n">shallow_structure</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tree/__init__.py:778,</span> in <span class="ni">map_structure_with_path_up_to</span><span class="nt">(***failed resolving arguments***)</span>
<span class="g g-Whitespace">    </span><span class="mi">776</span> <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="g g-Whitespace">    </span><span class="mi">777</span> <span class="k">for</span> <span class="n">path_and_values</span> <span class="ow">in</span> <span class="n">_multiyield_flat_up_to</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">778</span>   <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">path_and_values</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">779</span> <span class="k">return</span> <span class="n">unflatten_as</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/python/internal/backend/jax/nest.py:326,</span> in <span class="ni">map_structure_up_to.&lt;locals&gt;.&lt;lambda&gt;</span><span class="nt">(_, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">323</span> <span class="k">def</span> <span class="nf">map_structure_up_to</span><span class="p">(</span><span class="n">shallow_structure</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">structures</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span>   <span class="k">return</span> <span class="n">map_structure_with_tuple_paths_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">325</span>       <span class="n">shallow_structure</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">326</span>       <span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">),</span>  <span class="c1"># Discards path.</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>       <span class="o">*</span><span class="n">structures</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>       <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/bijectors/bijector.py:1707,</span> in <span class="ni">Bijector.forward_dtype.&lt;locals&gt;.&lt;lambda&gt;</span><span class="nt">(x)</span>
<span class="g g-Whitespace">   </span><span class="mi">1701</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest_util</span><span class="o">.</span><span class="n">broadcast_structure</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1702</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1703</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1704</span>   <span class="c1"># Make sure inputs are compatible with statically-known dtype.</span>
<span class="g g-Whitespace">   </span><span class="mi">1705</span>   <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1706</span>       <span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1707</span>       <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">dtype_util</span><span class="o">.</span><span class="n">convert_to_dtype</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1708</span>       <span class="n">nest_util</span><span class="o">.</span><span class="n">coerce_structure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forward_min_event_ndims</span><span class="p">,</span> <span class="n">dtype</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1709</span>       <span class="n">check_types</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1711</span> <span class="n">output_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_dtype</span><span class="p">(</span><span class="n">input_dtype</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1712</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1713</span>   <span class="c1"># kwargs may alter dtypes themselves, but we currently require</span>
<span class="g g-Whitespace">   </span><span class="mi">1714</span>   <span class="c1"># structure to be statically known.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/tensorflow_probability/substrates/jax/internal/dtype_util.py:247,</span> in <span class="ni">convert_to_dtype</span><span class="nt">(tensor_or_dtype, dtype, dtype_hint)</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor_or_dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">246</span>   <span class="n">dt</span> <span class="o">=</span> <span class="n">base_dtype</span><span class="p">(</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">dtype_hint</span> <span class="ow">or</span> <span class="n">tensor_or_dtype</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">247</span> <span class="k">elif</span> <span class="n">np</span><span class="o">.</span><span class="n">issctype</span><span class="p">(</span><span class="n">tensor_or_dtype</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span>   <span class="n">dt</span> <span class="o">=</span> <span class="n">base_dtype</span><span class="p">(</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">dtype_hint</span> <span class="ow">or</span> <span class="n">tensor_or_dtype</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">250</span>   <span class="c1"># If this is a Python object, call `convert_to_tensor` and grab the dtype.</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span>   <span class="c1"># Note that this will add ops in graph-mode; we may want to consider</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span>   <span class="c1"># other ways to handle this case.</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/numpy/__init__.py:397,</span> in <span class="ni">__getattr__</span><span class="nt">(attr)</span>
<span class="g g-Whitespace">    </span><span class="mi">394</span>     <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="n">__former_attrs__</span><span class="p">[</span><span class="n">attr</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">396</span> <span class="k">if</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">__expired_attributes__</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">397</span>     <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">398</span>         <span class="sa">f</span><span class="s2">&quot;`np.</span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">` was removed in the NumPy 2.0 release. &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">399</span>         <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">__expired_attributes__</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">400</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">402</span> <span class="k">if</span> <span class="n">attr</span> <span class="o">==</span> <span class="s2">&quot;chararray&quot;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">403</span>     <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">404</span>         <span class="s2">&quot;`np.chararray` is deprecated and will be removed from &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">405</span>         <span class="s2">&quot;the main namespace in the future. Use an array with a string &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">406</span>         <span class="s2">&quot;or bytes dtype instead.&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="ne">AttributeError</span>: `np.issctype` was removed in the NumPy 2.0 release. Use `issubclass(rep, np.generic)` instead.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate the trained MLP on input_grid</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">posterior_predictive_grid</span><span class="p">(</span><span class="n">input_grid</span><span class="p">,</span> <span class="n">w_means</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sigmoid_fn</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Plot the final result</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;CMGF-EKF One-Pass Trained MLP Classifier&quot;</span>
<span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">Z</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/cd57279133f78b54543b8e39c52211272fa3a4ff69f20b7bc9111c215fce3ac0.png" src="../../_images/cd57279133f78b54543b8e39c52211272fa3a4ff69f20b7bc9111c215fce3ac0.png" />
</div>
</div>
<p>Next, we visualize the training procedure by evaluating the intermediate steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">intermediate_steps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">99</span><span class="p">,</span> <span class="mi">199</span><span class="p">,</span> <span class="mi">299</span><span class="p">,</span> <span class="mi">399</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">axi</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">intermediate_steps</span><span class="p">,</span> <span class="n">ax</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">Zi</span> <span class="o">=</span> <span class="n">posterior_predictive_grid</span><span class="p">(</span><span class="n">input_grid</span><span class="p">,</span> <span class="n">w_means</span><span class="p">[</span><span class="n">step</span><span class="p">],</span> <span class="n">sigmoid_fn</span><span class="p">)</span>
    <span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;step=</span><span class="si">{</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">axi</span><span class="p">,</span> <span class="nb">input</span><span class="p">[:</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">output</span><span class="p">[:</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">Zi</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/bd0b79744766f2064f2c07c596b7d7e5471105a0c36ab5b59e505d227a2b87ad.png" src="../../_images/bd0b79744766f2064f2c07c596b7d7e5471105a0c36ab5b59e505d227a2b87ad.png" />
</div>
</div>
<p>Finally, we generate a video of the MLP-Classifier being trained.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.animation</span> <span class="k">as</span> <span class="nn">animation</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
    <span class="n">w_curr</span> <span class="o">=</span> <span class="n">w_means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">Zi</span> <span class="o">=</span> <span class="n">posterior_predictive_grid</span><span class="p">(</span><span class="n">input_grid</span><span class="p">,</span> <span class="n">w_means</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sigmoid_fn</span><span class="p">)</span>
    <span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;CMGF-EKF-MLP (</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/500)&#39;</span>
    <span class="n">plot_posterior_predictive</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">input</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">output</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">title</span><span class="p">,</span> <span class="n">input_grid</span><span class="p">,</span> <span class="n">Zi</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#fig, ax = plt.subplots(figsize=(6, 5))</span>
<span class="c1">#anim = animation.FuncAnimation(fig, animate, frames=500, interval=50)</span>
<span class="c1">#anim.save(&quot;cmgf_mlp_classifier.mp4&quot;, dpi=200, bitrate=-1, fps=24)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#HTML(anim.to_html5_video())</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="cmgf_logistic_regression_demo.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Online Logistic Regression using conditional moments Gaussian filter</p>
      </div>
    </a>
    <a class="right-next"
       href="cmgf_poisson_demo.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Fitting an LDS with Poisson Likelihood using conditional moments Gaussian filter</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-data">Create data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plotting-code">Plotting code</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-mlp">Define MLP</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-training-using-cmgf-ekf">Online Training Using CMGF-EKF</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Peter Chang, Giles Harper-Donnelly, Aleyna Kara, Xinglong Li, Scott Linderman, and Kevin Murphy
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2022, Peter Chang, Giles Harper-Donnelly, Aleyna Kara, Xinglong Li, Scott Linderman, and Kevin Murphy.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>